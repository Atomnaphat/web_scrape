from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from bs4 import BeautifulSoup
import pymongo
import time
from datetime import datetime
import re
import random

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ä‡πà‡∏ß‡∏¢‡∏î‡∏∂‡∏á‡∏•‡∏¥‡∏á‡∏Å‡πå‡∏à‡∏≤‡∏Å onclick
def extract_link_from_onclick(onclick_text):
    match = re.search(r"['\"](/product/[^'\"]+)['\"]", onclick_text)
    return f"https://www.thaiwatsadu.com{match.group(1)}" if match else "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏•‡∏¥‡∏á‡∏Å‡πå"

# URL ‡∏Ç‡∏≠‡∏á‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö
web = 'https://www.thaiwatsadu.com/th/category/‡∏ß‡∏±‡∏™‡∏î‡∏∏‡∏Å‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á-53'

# ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ MongoDB
client = pymongo.MongoClient("mongodb://localhost:27017/")
db = client["scraping_db"]
collection = db["thaiwatsadu_logs"]

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Chrome options
chrome_options = Options()
chrome_options.add_argument('--headless=new')
chrome_options.add_argument('--disable-gpu')
chrome_options.add_argument('--no-sandbox')
chrome_options.add_argument('--disable-dev-shm-usage')
chrome_options.add_argument('--window-size=1920,1080')
chrome_options.add_argument('--disable-blink-features=AutomationControlled')
chrome_options.add_argument('--disable-extensions')
chrome_options.add_argument('--disable-infobars')
chrome_options.add_argument('--disable-notifications')
chrome_options.add_argument('--disable-popup-blocking')
chrome_options.add_argument('--disable-web-security')
chrome_options.add_argument('--ignore-certificate-errors')
chrome_options.add_argument('--ignore-ssl-errors')
chrome_options.add_argument(f'--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/{random.randint(90, 120)}.0.0.0 Safari/537.36')

# ‡πÄ‡∏û‡∏¥‡πà‡∏° experimental options
chrome_options.add_experimental_option('excludeSwitches', ['enable-automation', 'enable-logging'])
chrome_options.add_experimental_option('useAutomationExtension', False)

try:
    # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô WebDriver
    driver = webdriver.Chrome(options=chrome_options)
    
    # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ CDP
    driver.execute_cdp_cmd('Network.setUserAgentOverride', {
        "userAgent": f'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/{random.randint(90, 120)}.0.0.0 Safari/537.36'
    })
    driver.execute_cdp_cmd('Page.addScriptToEvaluateOnNewDocument', {
        'source': '''
            Object.defineProperty(navigator, 'webdriver', {
                get: () => undefined
            })
        '''
    })
    
    print(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á URL: {web}")
    driver.get(web)
    
    # ‡∏£‡∏≠‡πÉ‡∏´‡πâ‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏™‡∏£‡πá‡∏à
    print("‡∏£‡∏≠‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö...")
    time.sleep(random.uniform(15, 20))
    
    # ‡∏£‡∏≠‡πÉ‡∏´‡πâ‡∏°‡∏µ‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡πÅ‡∏™‡∏î‡∏á‡πÉ‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö
    wait = WebDriverWait(driver, 30)
    try:
        # ‡∏£‡∏≠‡πÉ‡∏´‡πâ‡∏°‡∏µ element ‡∏ó‡∏µ‡πà‡∏°‡∏µ class ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div.pt-1.md\\:pt-2.pb-2.bg-white.hover\\:shadow-md.cursor-pointer.rounded')))
        print("‡∏û‡∏ö element ‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤")
    except Exception as e:
        print(f"‡πÑ‡∏°‡πà‡∏û‡∏ö element ‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤: {str(e)}")
    
    # ‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠‡∏•‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÄ‡∏û‡∏¥‡πà‡∏°
    print("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠...")
    driver.execute_script("window.scrollTo(0, document.body.scrollHeight/2);")
    time.sleep(random.uniform(5, 8))
    driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
    time.sleep(random.uniform(5, 8))
    
    # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå HTML
    soup = BeautifulSoup(driver.page_source, 'html.parser')
    
    # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
    products = soup.find_all('div', class_='pt-1 md:pt-2 pb-2 bg-white hover:shadow-md cursor-pointer rounded')
    print(f"‡∏û‡∏ö‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {len(products)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
    
    if len(products) == 0:
        print("\nDebug: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö HTML ‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ:")
        print(driver.page_source[:2000])
        raise Exception("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡πÉ‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö")

    data = []
    incomplete_count = 0

    for product in products:
        try:
            # Debug: Print product HTML
            print("\n‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤:")
            print(product.prettify()[:200])
            
            # ‡∏´‡∏≤‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤
            title = None
            title_elem = product.find('div', class_='font-semibold text-lg leading-5 hover:underline')
            if title_elem:
                title = title_elem.text.strip()
            else:
                # ‡∏•‡∏≠‡∏á‡∏´‡∏≤ title ‡∏î‡πâ‡∏ß‡∏¢‡∏ß‡∏¥‡∏ò‡∏µ‡∏≠‡∏∑‡πà‡∏ô
                title_elem = product.find('div', class_=lambda x: x and 'font-semibold' in x)
                if title_elem:
                    title = title_elem.text.strip()
                else:
                    title_elem = product.find('div', class_=lambda x: x and 'text-lg' in x)
                    if title_elem:
                        title = title_elem.text.strip()
            
            if not title:
                title = "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤"

            # ‡∏´‡∏≤‡∏£‡∏≤‡∏Ñ‡∏≤
            price = None
            price_elem = product.find('div', class_='text-grayDark text-sm leading-3 line-through')
            if price_elem:
                price = price_elem.text.strip()
            else:
                # ‡∏•‡∏≠‡∏á‡∏´‡∏≤‡∏£‡∏≤‡∏Ñ‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡∏ß‡∏¥‡∏ò‡∏µ‡∏≠‡∏∑‡πà‡∏ô
                price_elem = product.find('div', class_=lambda x: x and 'text-grayDark' in x)
                if price_elem:
                    price = price_elem.text.strip()
                else:
                    price_elem = product.find('div', class_=lambda x: x and 'line-through' in x)
                    if price_elem:
                        price = price_elem.text.strip()
            
            if not price:
                price = "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏£‡∏≤‡∏Ñ‡∏≤"

            # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏•‡∏¥‡∏á‡∏Å‡πå
            link = "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏•‡∏¥‡∏á‡∏Å‡πå"
            link_elem = product.find('a', href=True)
            if link_elem:
                if link_elem.has_attr('data-url'):
                    link = f"https://www.thaiwatsadu.com{link_elem['data-url']}"
                elif link_elem.has_attr('onclick'):
                    link = extract_link_from_onclick(link_elem['onclick'])
                else:
                    link = link_elem['href']
                    if not link.startswith('http'):
                        link = f"https://www.thaiwatsadu.com{link}"

            print(f"‚úÖ {title} - {price} - {link}")

            data.append({
                "title": title,
                "price": price,
                "link": link,
                "scraped_at": datetime.now()
            })

        except Exception as e:
            incomplete_count += 1
            print(f"‚ö†Ô∏è ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤: {str(e)}")

    print(f"‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå: {len(data)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
    print(f"‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå: {incomplete_count} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")

    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á MongoDB
    if data:
        collection.insert_many(data)
        print("üìå ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á MongoDB ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")

except Exception as e:
    print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {str(e)}")
    print("Stack trace:", e.__traceback__)

finally:
    if 'driver' in locals():
        driver.quit()
